package at.ac.tuwien.ifs.es.middleware.service.exploration.exploitation;

import at.ac.tuwien.ifs.es.middleware.dto.exploration.context.ExplorationContext;
import at.ac.tuwien.ifs.es.middleware.dto.exploration.context.IterableResourcesContext;
import at.ac.tuwien.ifs.es.middleware.dto.exploration.context.ResourceList;
import at.ac.tuwien.ifs.es.middleware.dto.exploration.context.result.Resource;
import at.ac.tuwien.ifs.es.middleware.service.exploration.payload.VoidPayload;
import at.ac.tuwien.ifs.es.middleware.dto.exploration.util.BlankOrIRIJsonUtil;
import at.ac.tuwien.ifs.es.middleware.dto.sparql.SelectQueryResult;
import at.ac.tuwien.ifs.es.middleware.service.exception.ExplorationFlowSpecificationException;
import at.ac.tuwien.ifs.es.middleware.service.exploration.registry.RegisterForExplorationFlow;
import at.ac.tuwien.ifs.es.middleware.service.knowledgegraph.sparql.SPARQLService;
import com.fasterxml.jackson.core.JsonPointer;
import com.fasterxml.jackson.databind.node.JsonNodeFactory;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.stream.Collectors;
import org.apache.commons.lang.text.StrSubstitutor;
import org.apache.commons.rdf.api.BlankNodeOrIRI;
import org.apache.commons.rdf.api.Literal;
import org.apache.commons.rdf.api.RDFTerm;
import org.springframework.context.annotation.Lazy;
import org.springframework.stereotype.Component;

@Lazy
@Component
@RegisterForExplorationFlow("esm.exploit.class.distribution")
public class ClassDistributionAnalysis implements ExploitationOperator<VoidPayload> {

  private static final int LOAD_LIMIT = 10000;

  private static final String CLASS_DIST_QUERY =
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n"
          + "    select DISTINCT ?class (count(*) as ?cnt) where {\n"
          + "      VALUES ?s {\n"
          + "        ${resources}\n"
          + "      }\n"
          + "    ?s a/rdfs:subClassOf* ?class.\n"
          + "    FILTER (isIRI(?class)).\n"
          + "} GROUP BY ?class";

  private JsonPointer countPointer = JsonPointer.compile("/count");

  private SPARQLService sparqlService;

  public ClassDistributionAnalysis(SPARQLService sparqlService) {
    this.sparqlService = sparqlService;
  }

  @Override
  public Class<VoidPayload> getParameterClass() {
    return VoidPayload.class;
  }

  @Override
  public ExplorationContext apply(ExplorationContext context, VoidPayload payload) {
    if (context instanceof IterableResourcesContext) {
      Iterator<Resource> resourceIterator = ((IterableResourcesContext) context)
          .getResourceIterator();
      /* fetch the class distribution */
      Map<Resource, Long> classDistributionMap = new HashMap<>();
      while (resourceIterator.hasNext()) {
        Set<Resource> resourceSet = new HashSet<>();
        for (int i = 0; resourceIterator.hasNext() && i < LOAD_LIMIT; i++) {
          resourceSet.add(resourceIterator.next());
        }
        List<Map<String, RDFTerm>> results = sparqlService.<SelectQueryResult>query(
            new StrSubstitutor(Collections.singletonMap("resources", resourceSet.stream()
                .map(BlankOrIRIJsonUtil::stringForSPARQLResourceOf)
                .collect(Collectors.joining("\n")))).replace(CLASS_DIST_QUERY), true).value();
        for (Map<String, RDFTerm> row : results) {
          Resource classResource = new Resource((BlankNodeOrIRI) row.get("class"));
          Long classNumberValue = classDistributionMap.getOrDefault(classResource, 0L) + Long
              .parseLong(((Literal) row.get("cnt")).getLexicalForm());
          classDistributionMap.put(classResource, classNumberValue);
        }
      }
      /* pass the class distribution as own resource list context */
      ResourceList resourceList = new ResourceList(classDistributionMap.keySet());
      for (Map.Entry<Resource, Long> row : classDistributionMap.entrySet()) {
        resourceList.putValuesData(row.getKey().getId(), countPointer,
            JsonNodeFactory.instance.numberNode(row.getValue()));
      }
      return resourceList;
    } else {
      throw new ExplorationFlowSpecificationException(
          "The given exploration flow is not valid, because a class distribution operator needs a context with an iterable collection get resources.");
    }
  }
}
